{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 16000\n",
    "test_size = 4000\n",
    "data_dir = \"set7_orbitron_preprocessed_forks_dim_spinners\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 - 0.5\n",
    "    o_y = float(y) / 2 - 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
    "    return transform_matrix\n",
    "\n",
    "def apply_affine_transform(theta=0, tx=0, ty=0, shear=0, zx=1, zy=1, row_axis=2, col_axis=1):\n",
    "    theta = np.deg2rad(theta)\n",
    "    rotation_matrix = np.array(\n",
    "        [\n",
    "            [np.cos(theta), -np.sin(theta), 0],\n",
    "            [np.sin(theta), np.cos(theta), 0],\n",
    "            [0, 0, 1],\n",
    "        ]\n",
    "    )\n",
    "    transform_matrix = rotation_matrix\n",
    "\n",
    "    shift_matrix = np.array([[1, 0, tx], [0, 1, ty], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(transform_matrix, shift_matrix)\n",
    "\n",
    "    shear = np.deg2rad(shear)\n",
    "    shear_matrix = np.array(\n",
    "        [[1, -np.sin(shear), 0], [0, np.cos(shear), 0], [0, 0, 1]]\n",
    "    )\n",
    "    transform_matrix = np.dot(transform_matrix, shear_matrix)\n",
    "\n",
    "    zoom_matrix = np.array([[zx, 0, 0], [0, zy, 0], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(transform_matrix, zoom_matrix)\n",
    "\n",
    "    transform_matrix = transform_matrix_offset_center(\n",
    "        transform_matrix, 720, 1280\n",
    "    )\n",
    "\n",
    "    if col_axis > row_axis:\n",
    "        transform_matrix[:, [0, 1]] = transform_matrix[:, [1, 0]]\n",
    "        transform_matrix[[0, 1]] = transform_matrix[[1, 0]]\n",
    "\n",
    "    return transform_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Not actually annotating the images, just displaying the bounding boxes generated from unity\n",
    "def annotate(i, image, sub=None, cmap='gray', preprocessed=True, is_json=False):\n",
    "    if is_json:\n",
    "        with open(f'../TrainingData/TrainingKeys/image_{i}.json', \"r\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "\n",
    "        if not preprocessed:\n",
    "            x = int(json_data[\"position\"][\"x\"])\n",
    "            y = int(json_data['position']['y'])\n",
    "            w = int(json_data[\"position\"][\"z\"])\n",
    "            h = int(json_data[\"position\"][\"w\"])\n",
    "        else:\n",
    "            x = int(json_data[\"transformedPoint\"][\"x\"])\n",
    "            y = int(json_data['transformedPoint']['y'])\n",
    "            w = int(json_data[\"transformedPoint\"][\"z\"])\n",
    "            h = int(json_data[\"transformedPoint\"][\"w\"])\n",
    "    else:\n",
    "        with open(f'datasets/{data_dir}/train/labels/image_{i}.txt', \"r\") as file:\n",
    "            data = file.read().split(' ')\n",
    "            x = float(data[1])*720\n",
    "            y = float(data[2])*720\n",
    "            w = float(data[3])*720\n",
    "            h = float(data[4])*720\n",
    "\n",
    "    x1 = x + w/2\n",
    "    x2 = x - w/2\n",
    "    y1 = y + h/2\n",
    "    y2 = y - h/2\n",
    "\n",
    "    if sub:\n",
    "        ax = sub\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    \n",
    "    ax.imshow(image)\n",
    "\n",
    "    rect = patches.Rectangle((x2, y2), w, h, linewidth=2, edgecolor='g', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    # rect1 = patches.Rectangle((x-w/2, y-h/2), w, h, linewidth=2, edgecolor='b', facecolor='none')\n",
    "    # ax.add_patch(rect1)\n",
    "    circle = patches.Circle((x, y), radius=5, color='b')\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "    if sub:\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Shows results of yolo model prediction\n",
    "def predict(model, img):\n",
    "    results = model(img)\n",
    "    for r in results:\n",
    "        im_array = r.plot()\n",
    "        im = Image.fromarray(im_array[..., ::-1])\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_img = 4\n",
    "plt_size = 20\n",
    "\n",
    "is_json = False\n",
    "preprocessed = True\n",
    "\n",
    "# Picks random images to show the boudning boxes from unity\n",
    "if num_img != 1:\n",
    "    fig, ax = plt.subplots(num_img, 1, figsize=(plt_size, 720/1280*num_img*plt_size))\n",
    "j = 0\n",
    "for i in np.random.randint(0, 700, num_img):\n",
    "    print(i)\n",
    "    if is_json:\n",
    "        if preprocessed:\n",
    "            img = cv2.imread(f'../TrainingData/TrainingInputsPosition/image_{i}.jpg', cv2.IMREAD_COLOR)\n",
    "        else:\n",
    "            img = cv2.imread(f'../TrainingData/TrainingInputs/image_{i}.jpg', cv2.IMREAD_COLOR)\n",
    "    else:\n",
    "        img = cv2.imread(f'datasets/{data_dir}/train/images/image_{i}.jpg', cv2.IMREAD_COLOR)\n",
    "    print(img.shape, img.dtype, img.max(), img.min())\n",
    "    if num_img == 1:\n",
    "        annotate(i, img, preprocessed=preprocessed, is_json=is_json)\n",
    "    else:\n",
    "        annotate(i, img, ax[j], preprocessed=preprocessed, is_json=is_json)\n",
    "    j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def grayscale(img, show=False, save=False):\n",
    "    gray_img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "    if show:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(gray_img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    if save:\n",
    "        cv2.imwrite(img, gray_img)\n",
    "    return gray_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.append('..')\n",
    "import Utilities\n",
    "reload(Utilities)\n",
    "from Utilities import prepare_and_augment_image\n",
    "sys.path.remove('..')\n",
    "\n",
    "\n",
    "def get_info(i, augs):\n",
    "    img = cv2.imread(f'datasets/{data_dir}/train/images/image_{i}.jpg')\n",
    "\n",
    "    with open(f'datasets/{data_dir}/keys/image_{i}.json', \"r\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "\n",
    "    x = int(json_data[\"position\"][\"x\"])\n",
    "    y = int(json_data['position']['y'])\n",
    "    w = int(json_data[\"position\"][\"z\"])\n",
    "    h = int(json_data[\"position\"][\"w\"])\n",
    "\n",
    "    aug_img, params = prepare_and_augment_image(img, augs)\n",
    "\n",
    "    theta = params['theta']\n",
    "    tx = params['tx']\n",
    "    ty = params['ty']\n",
    "    zx = params['zx']\n",
    "    zy = params['zy']\n",
    "    shear = params['shear']\n",
    "\n",
    "    matrix = apply_affine_transform(theta, tx, ty, shear, zx, zy, row_axis=1, col_axis=2)\n",
    "    a = matrix[0,0]\n",
    "    b = matrix[0,1]\n",
    "    c = matrix[0,2]\n",
    "    d = matrix[1,0]\n",
    "    e = matrix[1,1]\n",
    "    f = matrix[1,2]\n",
    "\n",
    "    return img,aug_img,x,y,w,h,params,tx,ty,zx,zy,theta,matrix,a,b,c,d,e,f\n",
    "\n",
    "def draw_box(x, y, w, h, c):   \n",
    "    x2 = x - w/2\n",
    "    y2 = y - h/2\n",
    "    rect = patches.Rectangle((x2, y2), w, h, linewidth=2, edgecolor=c, facecolor='none')\n",
    "    axs[0].add_patch(rect)\n",
    "    circle = patches.Circle((x, y), radius=5, color='b')\n",
    "    axs[0].add_patch(circle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.append('..')\n",
    "import Utilities\n",
    "reload(Utilities)\n",
    "from Utilities import Augmentations\n",
    "sys.path.remove('..')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "augs = Augmentations(\n",
    "    zoom_range = 0.3, #0.3\n",
    "    width_shift_range = 0.2, #0.2\n",
    "    height_shift_range = 0.2, #0.2\n",
    "    shear_range = 0,\n",
    "    rotation_range = 0, #20\n",
    "    brightness_range = [0.7, 1.3],\n",
    "    max_overlay_objects = 3,\n",
    "    object_size = [64, 64],\n",
    "    blur_probability = 0.2,\n",
    ")\n",
    "\n",
    "for i in np.random.randint(0, 1600, 5):\n",
    "    img,aug_img,x,y,w,h,params,tx,ty,zx,zy,theta,matrix,a,b,c,d,e,f = get_info(i, augs)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 10))\n",
    "    annotate(i, aug_img, sub=axs[0])\n",
    "    annotate(i, img,sub=axs[1])\n",
    "\n",
    "    w /= zx\n",
    "    h /= zy\n",
    "    \n",
    "    x1 = (x-tx-720/2*(1-zx))/zx\n",
    "    y1 = (y-ty-1280/2*(1-zy))/zy\n",
    "    draw_box(x1, y1, w, h, 'r')\n",
    "\n",
    "    x2 = (x-f-d*y)/e\n",
    "    y2 = (y-c-b*x)/a\n",
    "    draw_box(x2, y2, w, h, 'm')\n",
    "\n",
    "    print(x,y)\n",
    "    print(matrix)\n",
    "    print(params)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "model1 = YOLO('model5_disarray_unpreprocessed.pt')\n",
    "\n",
    "for i in np.random.randint(20000, 25000, 3):\n",
    "    predict(model1, f'datasets/set5_disarray_unpreprocessed/val/images/image_{i}.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the module \n",
    "import cv2 \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# reading the video\n",
    "source = cv2.VideoCapture('terribleFight.avi') \n",
    "\n",
    "# Get total frames\n",
    "total_frames = int(source.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Create a progress bar\n",
    "progress_bar = tqdm(total=total_frames, desc=\"Processing frames\", ncols=100)\n",
    "\n",
    "# We need to set resolutions. \n",
    "# so, convert them from float to integer. \n",
    "frame_width = int(source.get(3)) \n",
    "frame_height = int(source.get(4)) \n",
    "   \n",
    "size = (frame_width, frame_height) \n",
    "\n",
    "result = cv2.VideoWriter('gray1.avi',  \n",
    "            cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "            10, size, 0) \n",
    "  \n",
    "# running the loop \n",
    "while True: \n",
    "    # extracting the frames \n",
    "    ret, img = source.read() \n",
    "\n",
    "    # If frame read successfully\n",
    "    if ret:\n",
    "        # converting to gray-scale \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "        # write to gray-scale \n",
    "        result.write(gray)\n",
    "\n",
    "        # displaying the video \n",
    "        cv2.imshow(\"Live\", gray) \n",
    "\n",
    "        # Update the progress bar\n",
    "        progress_bar.update(1)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    # exiting the loop \n",
    "    key = cv2.waitKey(1) \n",
    "    if key == ord(\"q\"): \n",
    "        break\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('model7_orbitron_preprocessed_forks_dim_spinners.pt', task='predict')\n",
    "results = model('DisarrayFight2Trimmed.avi', show=True, save=True, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('model4_orbitron_preprocessed_forks.pt')\n",
    "model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "ort_session = ort.InferenceSession('model4_orbitron_preprocessed_forks.onnx')\n",
    "img = cv2.imread('datasets/set4_forks_preprocessed/val/images/image_20000.jpg', cv2.IMREAD_COLOR)\n",
    "img = cv2.resize(img, (736, 736))\n",
    "img = img.astype(np.float32)\n",
    "img /= 255.0\n",
    "img = img.transpose(2, 0, 1)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img.shape, img.dtype, img.max(), img.min()\n",
    "# cv2.imshow('img', img[0].transpose(1, 2, 0))\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "output = ort_session.run(None, {'images': img})  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = output[0][0].transpose(1,0)\n",
    "print(output[0].shape)\n",
    "max_conf = 0\n",
    "max_d = None\n",
    "for d in data:\n",
    "    conf = d[4]\n",
    "    # print(conf)\n",
    "    if conf > max_conf:\n",
    "        max_conf = conf\n",
    "        max_d = d\n",
    "print(max_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
